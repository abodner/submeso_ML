{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xarray as xr\n",
    "import xgcm \n",
    "from fastjmd95 import jmd95numba \n",
    "\n",
    "\n",
    "\n",
    "# paths to dataset\n",
    "PATH_2d = '/scratch/ab10313/pleiades/03_south_atlantic/2d_data/'\n",
    "PATH_3d = '/scratch/ab10313/pleiades/03_south_atlantic/3d_data/'\n",
    "\n",
    "# make diirectory for preprocessed variables\n",
    "PATH_PP = '/scratch/ab10313/pleiades/03_south_atlantic/preprcossed_data/'\n",
    "#os.mkdir(PATH_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 2d data\n",
    "ds_HBL = xr.open_dataset(PATH_2d+'ds_HBL.nc',engine=\"h5netcdf\")\n",
    "ds_Q = xr.open_dataset(PATH_2d+'ds_Q.nc',engine=\"h5netcdf\")\n",
    "ds_TAUX = xr.open_dataset(PATH_2d+'ds_TAUX.nc',engine=\"h5netcdf\")\n",
    "ds_TAUY = xr.open_dataset(PATH_2d+'ds_TAUY.nc',engine=\"h5netcdf\")\n",
    "\n",
    "\n",
    "# load 3d data\n",
    "ds_T = xr.open_dataset(PATH_3d+'ds_T.nc',engine=\"h5netcdf\")\n",
    "ds_S = xr.open_dataset(PATH_3d+'ds_S.nc',engine=\"h5netcdf\")\n",
    "ds_U = xr.open_dataset(PATH_3d+'ds_U.nc',engine=\"h5netcdf\")\n",
    "ds_V = xr.open_dataset(PATH_3d+'ds_V.nc',engine=\"h5netcdf\")\n",
    "ds_W = xr.open_dataset(PATH_3d+'ds_W.nc',engine=\"h5netcdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find min and max i and j to crop to 10X10 degrees\n",
    "\n",
    "i_min = np.max([ds_HBL.i.min().values,ds_Q.i.min().values, ds_TAUX.i_g.min().values, ds_TAUY.i.min().values,\n",
    "                ds_T.i.min().values, ds_S.i.min().values, ds_U.i_g.min().values, ds_V.i.min().values, ds_W.i.min().values])\n",
    "\n",
    "\n",
    "i_max = np.min([ds_HBL.i.max().values,ds_Q.i.max().values, ds_TAUX.i_g.max().values, ds_TAUY.i.max().values,\n",
    "                ds_T.i.max().values, ds_S.i.max().values, ds_U.i_g.max().values, ds_V.i.max().values, ds_W.i.max().values])\n",
    "\n",
    "\n",
    "j_min = np.max([ds_HBL.j.min().values,ds_Q.j.min().values, ds_TAUX.j.min().values, ds_TAUY.j_g.min().values,\n",
    "                ds_T.j.min().values, ds_S.j.min().values, ds_U.j.min().values, ds_V.j_g.min().values, ds_W.j.min().values])\n",
    "\n",
    "\n",
    "j_max = np.min([ds_HBL.j.max().values,ds_Q.j.max().values, ds_TAUX.j.max().values, ds_TAUY.j_g.max().values,\n",
    "                ds_T.j.max().values, ds_S.j.max().values, ds_U.j.max().values, ds_V.j_g.max().values, ds_W.j.max().values])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define slice to 480 index\n",
    "\n",
    "if i_min+480>i_max:\n",
    "    print('cropped region error in i')\n",
    "elif j_min+480>j_max:\n",
    "    print('cropped region error in j')\n",
    "else:\n",
    "    i_slice = slice(i_min,i_min+480)\n",
    "    j_slice = slice(j_min,j_min+480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "ds_2d =xr.merge([ds_HBL.sel(i=i_slice,j=j_slice), ds_Q.sel(i=i_slice,j=j_slice),\n",
    "                 ds_TAUX.sel(i_g=i_slice,j=j_slice), ds_TAUY.sel(i=i_slice,j_g=j_slice)])\n",
    "\n",
    "\n",
    "ds_3d =xr.merge([ds_T.sel(i=i_slice,j=j_slice), ds_S.sel(i=i_slice,j=j_slice),\n",
    "                 ds_U.sel(i_g=i_slice,j=j_slice), ds_V.sel(i=i_slice,j_g=j_slice), ds_W.sel(i=i_slice,j=j_slice)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grids \n",
    "\n",
    "grid_2d = xgcm.Grid(ds_2d)\n",
    "\n",
    "grid_3d = xgcm.Grid(ds_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma from temp and salt, using the fastjmd95 package\n",
    "\n",
    "    \n",
    "# reference density \n",
    "rho0 = 1000 #kg/m^3\n",
    "\n",
    "# potential density anomaly \n",
    "# with the reference pressure of 0 dbar and ρ0 = 1000 kg m−3\n",
    "sigma0 = jmd95numba.rho(ds_3d.Salt.chunk(chunks={'time': 1, 'j': ds_3d.j.size, 'i': ds_3d.i.size}),\n",
    "                         ds_3d.Theta.chunk(chunks={'time': 1, 'j': ds_3d.j.size, 'i': ds_3d.i.size}), 0) - rho0\n",
    "\n",
    "sigma0 = sigma0.rename('sigma0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma0 at 10m depth for reference\n",
    "\n",
    "sigma0_10m = sigma0.isel(k=6).broadcast_like(sigma0).chunk(chunks={'time': 1, 'j': ds_3d.j.size, 'i': ds_3d.i.size})\n",
    "delta_sigma = sigma0 - sigma0_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gravity\n",
    "G = 9.81 #m/s^2\n",
    "\n",
    "# buoyancy\n",
    "B = -G*sigma0/rho0\n",
    "B = B.rename('Buoyancy')\n",
    "\n",
    "# save buoyancy averaged over mixed layer depth:\n",
    "B.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'B.nc',engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/xarray/core/indexing.py:1374: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/ext3/miniconda3/lib/python3.9/site-packages/xarray/core/indexing.py:1374: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/ext3/miniconda3/lib/python3.9/site-packages/xarray/core/indexing.py:1374: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "# vertical buoyancy gradient (stratification)\n",
    "Nsquared = B.diff(dim='k')/B.drF\n",
    "Nsquared.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'Nsquared.nc',engine='h5netcdf')\n",
    "\n",
    "# horizontal x buoyancy gradient\n",
    "B_x = B.diff(dim='i')/B.dxF\n",
    "B_x.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'B_x.nc',engine='h5netcdf')\n",
    "\n",
    "# horizontal y buoyancy gradient\n",
    "B_y = B.diff(dim='j')/B.dyF\n",
    "B_y.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'B_y.nc',engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed layer depth\n",
    "\n",
    "# mixed layer depth\n",
    "MLD = sigma0.Z.broadcast_like(sigma0).where(delta_sigma<=0.03).min(dim=\"k\",skipna=True).chunk(chunks={'time': 1, 'j': sigma0.j.size, 'i': sigma0.i.size}).rename('Mixed Layer Depth')\n",
    "MLD.to_netcdf(PATH_PP+'MLD.nc',engine='h5netcdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# interp velocities and average over MLD\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m U_interp \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_3d\u001b[49m\u001b[38;5;241m.\u001b[39minterp(ds_3d\u001b[38;5;241m.\u001b[39mU,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m U_interp\u001b[38;5;241m.\u001b[39mwhere(delta_sigma\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m,skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_netcdf(PATH_PP\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU.nc\u001b[39m\u001b[38;5;124m'\u001b[39m,engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m V_interp \u001b[38;5;241m=\u001b[39m grid_3d\u001b[38;5;241m.\u001b[39minterp(ds_3d\u001b[38;5;241m.\u001b[39mV,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_3d' is not defined"
     ]
    }
   ],
   "source": [
    "# interp velocities and average over MLD\n",
    "\n",
    "U_interp = grid_3d.interp(ds_3d.U,'X', boundary='extend')\n",
    "U_interp.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'U.nc',engine='h5netcdf')\n",
    "\n",
    "V_interp = grid_3d.interp(ds_3d.V,'Y', boundary='extend')\n",
    "V_interp.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'V.nc',engine='h5netcdf')\n",
    "\n",
    "W_interp = grid_3d.interp(ds_3d.W,'Z', boundary='extend')\n",
    "W_interp.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'W.nc',engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buoyancy fluxes\n",
    "\n",
    "UB = U_interp * B\n",
    "UB.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'UB.nc',engine='h5netcdf')\n",
    "\n",
    "VB = V_interp * B\n",
    "VB.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'VB.nc',engine='h5netcdf')\n",
    "\n",
    "WB = UW_interp * B\n",
    "WB.where(delta_sigma<=0.03).mean(dim=\"k\",skipna=True).to_netcdf(PATH_PP+'WB.nc',engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp tau\n",
    "\n",
    "TAUX_interp = grid_2d.interp(ds_2d.oceTAUX,'X', boundary='extend')\n",
    "TAUX_interp.to_netcdf(PATH_PP+'TAUX.nc',engine='h5netcdf')\n",
    "\n",
    "TAUY_interp = grid_2d.interp(ds_2d.oceTAUY,'Y', boundary='extend')\n",
    "TAUY_interp.to_netcdf(PATH_PP+'TAUY.nc',engine='h5netcdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "submeso_env",
   "language": "python",
   "name": "submeso_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
