{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14f720046530>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "np.random.seed(14)  # For reproducibility\n",
    "torch.manual_seed(14)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input and output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input shape:\n",
      "(430, 4, 40, 37)\n",
      "\n",
      "Y output shape:\n",
      "(430, 3, 40, 37)\n",
      "\n",
      "grad b shape:\n",
      "(430, 3, 40, 37)\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data, convert to numpy and stack channels\n",
    "\n",
    "BASE = '/scratch/ab10313/submeso_ML_data/'\n",
    "FULL_PATH_PP = glob.glob(BASE+'*/preprocessed_data/')\n",
    "\n",
    "# X INPUT\n",
    "# should we normalize here?\n",
    "ds_Bm = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Bm_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_Um = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Um_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_Vm = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Vm_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_Wm = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Wm_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "\n",
    "X_input = np.stack([ds_Bm,ds_Um,ds_Vm,ds_Wm],axis=1)\n",
    "print('X input shape:')\n",
    "print( X_input.shape)\n",
    "print('')\n",
    "\n",
    "\n",
    "# Y OUTPUT\n",
    "# should we normalize here?\n",
    "ds_UsBs = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'UsBs_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_VsBs = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'VsBs_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_WsBs = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'WsBs_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "\n",
    "Y_output = np.stack([ds_UsBs,ds_VsBs,ds_WsBs],axis=1)\n",
    "print('Y output shape:')\n",
    "print(Y_output.shape)\n",
    "print('')\n",
    "\n",
    "\n",
    "# GRAD B\n",
    "# should we normalize here?\n",
    "ds_Bm_x = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Bm_x_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_Bm_y = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Bm_y_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "ds_Bm_z = xr.open_mfdataset(glob.glob(BASE+'*/preprocessed_data/'+'Bm_z_MLD_lowres.nc'),concat_dim='time',combine ='nested').__xarray_dataarray_variable__.to_numpy()[:,:,:-3]\n",
    "\n",
    "grad_b = np.stack([ds_Bm_x,ds_Bm_y,ds_Bm_z],axis=1)\n",
    "print('grad b shape:')\n",
    "print( grad_b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly generate train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train 80.0%, test 10.0%, val 10.0%\n",
      "no overlapping indecies\n"
     ]
    }
   ],
   "source": [
    "# randomnly generate train, test and validation time indecies \n",
    "import random\n",
    "time_ind = X_input.shape[0]\n",
    "rand_ind = np.arange(time_ind)\n",
    "rand_seed = 14\n",
    "random.Random(rand_seed).shuffle(rand_ind)\n",
    "train_percent = 0.8\n",
    "test_percent = 0.1 \n",
    "print(f\"Dataset: train {np.round(train_percent*100)}%, test {np.round(test_percent*100)}%, val {np.round((1-train_percent-test_percent)*100)}%\")\n",
    "train_ind, test_ind, val_ind =  rand_ind[:round(train_percent*time_ind)], rand_ind[round(train_percent*time_ind):round((train_percent+test_percent)*time_ind)], rand_ind[round((train_percent+test_percent)*time_ind):]                                                                        \n",
    "\n",
    "# check no overlapping indecies\n",
    "if np.intersect1d(train_ind, test_ind).any() or np.intersect1d(train_ind, val_ind).any() or np.intersect1d(val_ind, test_ind).any():\n",
    "    print('overlapping indecies')\n",
    "else:\n",
    "    print ('no overlapping indecies')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defined train, test and val dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "X input shape:\n",
      "(344, 4, 40, 37)\n",
      "Y output shape:\n",
      "(344, 3, 40, 37)\n",
      "grad b shape:\n",
      "(344, 3, 40, 37)\n",
      "\n",
      "TEST\n",
      "X input shape:\n",
      "(43, 4, 40, 37)\n",
      "Y output shape:\n",
      "(43, 3, 40, 37)\n",
      "grad b shape:\n",
      "(43, 3, 40, 37)\n",
      "\n",
      "VAL\n",
      "X input shape:\n",
      "(43, 4, 40, 37)\n",
      "Y output shape:\n",
      "(43, 3, 40, 37)\n",
      "grad b shape:\n",
      "(43, 3, 40, 37)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define X,Y pairs (state, subgrid fluxes) for local network.local_torch_dataset = Data.TensorDataset(\n",
    "BATCH_SIZE = 32  # Number of sample in each batch\n",
    "\n",
    "\n",
    "###### training dataset #######\n",
    "torch_dataset_train = Data.TensorDataset(\n",
    "    torch.from_numpy(X_input[train_ind]).double(),\n",
    "    torch.from_numpy(Y_output[train_ind]).double(),\n",
    "    torch.from_numpy(grad_b[train_ind]).double(),\n",
    ")\n",
    "\n",
    "loader_train = Data.DataLoader(\n",
    "    dataset=torch_dataset_train, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "print('TRAIN')\n",
    "print('X input shape:')\n",
    "print( X_input[train_ind].shape)\n",
    "print('Y output shape:')\n",
    "print( Y_output[train_ind].shape)\n",
    "print('grad b shape:')\n",
    "print( grad_b[train_ind].shape)\n",
    "print('')\n",
    "\n",
    "###### test dataset #######\n",
    "torch_dataset_test = Data.TensorDataset(\n",
    "    torch.from_numpy(X_input[test_ind]).double(),\n",
    "    torch.from_numpy(Y_output[test_ind]).double(),\n",
    "    torch.from_numpy(grad_b[test_ind]).double(),\n",
    "    \n",
    ")\n",
    "\n",
    "loader_test = Data.DataLoader(\n",
    "    dataset=torch_dataset_test, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "print('TEST')\n",
    "print('X input shape:')\n",
    "print( X_input[test_ind].shape)\n",
    "print('Y output shape:')\n",
    "print( Y_output[test_ind].shape)\n",
    "print('grad b shape:')\n",
    "print( grad_b[test_ind].shape)\n",
    "print('')\n",
    "\n",
    "###### validation dataset #######\n",
    "torch_dataset_val = Data.TensorDataset(\n",
    "    torch.from_numpy(X_input[val_ind]).double(),\n",
    "    torch.from_numpy(Y_output[val_ind]).double(),\n",
    "    torch.from_numpy(grad_b[val_ind]).double(),\n",
    ")\n",
    "\n",
    "loader_val = Data.DataLoader(\n",
    "    dataset=torch_dataset_val, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "print('VAL')\n",
    "print('X input shape:')\n",
    "print( X_input[val_ind].shape)\n",
    "print('Y output shape:')\n",
    "print( Y_output[val_ind].shape)\n",
    "print('grad b shape:')\n",
    "print( grad_b[val_ind].shape)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN skew flux 9 output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network structure in pytorch\n",
    "#import torch.nn.functional as FF\n",
    "\n",
    "#class CNN_skew(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super().__init__()\n",
    "#        self.conv1 = nn.Conv2d(4, 128, 5,padding=(2,2))  # 4 inputs, 128 neurons for first hidden layer\n",
    "#        self.conv2 = nn.Conv2d(128, 64, 5,padding=(2,2))  # 128 inputs, 64 neurons for first hidden layer\n",
    "#        self.conv3 = nn.Conv2d(64, 32, 5,padding=(2,2))  # 64 inputs, 32 neurons for first hidden layer\n",
    "#        self.conv4 = nn.Conv2d(32, 16, 5,padding=(2,2))  # 32 inputs, 24 neurons for first hidden layer\n",
    "#        self.conv5 = nn.Conv2d(16, 9, 5,padding=(2,2))  # 32 inputs, 24 neurons for first hidden layer\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        x = FF.relu(self.conv1(x))\n",
    "#        x = FF.relu(self.conv2(x))\n",
    "#        x = FF.relu(self.conv3(x))\n",
    "#        x = FF.relu(self.conv4(x))\n",
    "#        x = self.conv5(x)\n",
    "#        return x\n",
    "    \n",
    "    \n",
    "import torch.nn.functional as FF\n",
    "\n",
    "class CNN_skew(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 64, 5,padding='same')  # 4 inputs, 128 neurons for first hidden layer\n",
    "        self.conv2 = nn.Conv2d(64, 32, 5,padding='same')  # 64 inputs, 32 neurons for first hidden layer\n",
    "        self.conv3 = nn.Conv2d(32, 9, 3,padding='same')  # 32 inputs, 24 neurons for first hidden layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = FF.relu(self.conv1(x))\n",
    "        x = FF.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model: skew flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network skew flux\n",
    "def train_model_skew(net, criterion, trainloader, optimizer):\n",
    "    net.train()\n",
    "    test_loss = 0\n",
    "    for step, (batch_x, batch_y, batch_g) in enumerate(trainloader):  # for each training step\n",
    "        b_x = Variable(batch_x)  # Inputs\n",
    "        b_y = Variable(batch_y)  # outputs\n",
    "        b_grad = Variable(batch_g) # grad b\n",
    "        prediction = net(b_x)\n",
    "        \n",
    "        prediction_reshape = torch.reshape(prediction, (3, 3,prediction.shape[0],prediction.shape[2],prediction.shape[3]))\n",
    "        grad_b_reshape = torch.reshape(b_grad, (3, b_grad.shape[0],b_grad.shape[2],b_grad.shape[3]))\n",
    "        b_y_reshape = torch.reshape(b_y, (3, b_y.shape[0],b_y.shape[2],b_y.shape[3]))\n",
    "        \n",
    "        # Calculating loss to find J which is the prediction\n",
    "        loss = criterion(torch.matmul(prediction_reshape,b_grad), b_y)  \n",
    "        optimizer.zero_grad()  # clear gradients for next train\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients to update weights\n",
    "\n",
    "\n",
    "def test_model_skew(net, criterion, trainloader, optimizer, text=\"validation\"):\n",
    "    net.eval()  # Evaluation mode (important when having dropout layers)\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(\n",
    "            trainloader\n",
    "        ):  # for each training step\n",
    "            b_x = Variable(batch_x)  # Inputs\n",
    "            b_y = Variable(batch_y)  # outputs\n",
    "            prediction = net(b_x)\n",
    "            # Calculating loss to find J which is the prediction\n",
    "            loss = criterion(prediction*grad_b, b_y)\n",
    "            test_loss = test_loss + loss.data.numpy()  # Keep track of the loss\n",
    "        test_loss /= len(trainloader)  # dividing by the number of batches\n",
    "        #         print(len(trainloader))\n",
    "        print(text + \" loss:\", test_loss)\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # MSE loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/state/partition1/job-26268498/ipykernel_3868664/3882298193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[0;31m# train_model_direct(cnn_submeso, criterion, loader_train, optimizer,  text=\"train\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_skew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_submeso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#test_model_direct(cnn_submeso, criterion, loader_val, optimizer, text=\"validation\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_skew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_submeso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/job-26268498/ipykernel_3868664/575528856.py\u001b[0m in \u001b[0;36mtrain_model_skew\u001b[0;34m(net, criterion, trainloader, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Calculating loss to find J which is the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_reshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear gradients for next train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(14)  # For reproducibility\n",
    "cnn_submeso = CNN_skew().double()\n",
    "\n",
    "n_epochs = 50  # Number of epocs could be increased\n",
    "optimizer = optim.Adam(cnn_submeso.parameters(), lr=0.03)\n",
    "validation_loss = list()\n",
    "train_loss = list()\n",
    "# time0 = time()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"epoch:\", epoch)\n",
    "   # train_model_direct(cnn_submeso, criterion, loader_train, optimizer,  text=\"train\")\n",
    "    train_loss.append(train_model_skew(cnn_submeso, criterion, loader_train, optimizer))\n",
    "    #test_model_direct(cnn_submeso, criterion, loader_val, optimizer, text=\"validation\")\n",
    "    validation_loss.append(test_model_skew(cnn_submeso, criterion, loader_val, optimizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
